#shared.py
# Description:
# This file, shared.py, is a core component responsible for managing shared resources and data for different modules in the Ragnar project.
# It handles the initialization and configuration of paths, logging, fonts, and images. Additionally, it sets up the environment, 
# creates necessary directories and files, and manages the loading and saving of configuration settings.
# 
# Key functionalities include:
# - Initializing various paths used by the application, including directories for configuration, data, actions, web resources, and logs.
# - Setting up the environment, including the e-paper display, network knowledge base, and actions JSON configuration.
# - Loading and managing fonts and images required for the application's display.
# - Handling the creation and management of a live status file to store the current status of network scans.
# - Managing configuration settings, including loading default settings, updating, and saving configurations to a JSON file.
# - Providing utility functions for reading and writing data to CSV files, updating statistics, and wrapping text for display purposes.

import os
import re
import json
import importlib
import random
import time
import csv
import logging
import subprocess
import threading
from datetime import datetime
from PIL import Image, ImageFont 
from logger import Logger
from epd_helper import EPDHelper


logger = Logger(name="shared.py", level=logging.DEBUG) # Create a logger object 

class SharedData:
    """Shared data between the different modules."""
    def __init__(self):
        self.initialize_paths() # Initialize the paths used by the application
        self.status_list = [] 
        self.last_comment_time = time.time() # Last time a comment was displayed
        self._stats_lock = threading.Lock()  # Thread-safe lock for update_stats()
        self.default_config = self.get_default_config() # Default configuration of the application  
        self.config = self.default_config.copy() # Configuration of the application
        # Load existing configuration first
        self.load_config()

        # Update MAC blacklist without immediate save
        self.update_mac_blacklist()
        self.setup_environment(clear_console=False) # Setup the environment without clearing console
        self.initialize_variables() # Initialize the variables used by the application
        self.load_gamification_data()  # Load persistent gamification progress

        # Initialize network intelligence (after paths and config are ready)
        self.network_intelligence = None
        self.initialize_network_intelligence()
        
        self.create_livestatusfile() 
        self.load_fonts() # Load the fonts used by the application
        self.load_images() # Load the images used by the application
        # self.create_initial_image() # Create the initial image displayed on the screen
        
    def initialize_network_intelligence(self):
        """Initialize the network intelligence system"""
        try:
            from network_intelligence import NetworkIntelligence
            self.network_intelligence = NetworkIntelligence(self)
            logger.info("Network intelligence system initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize network intelligence: {e}")
            self.network_intelligence = None

    def initialize_paths(self):
        """Initialize the paths used by the application."""
        """Folders paths"""
        self.currentdir = os.path.dirname(os.path.abspath(__file__))
        # Directories directly under currentdir
        self.configdir = os.path.join(self.currentdir, 'config')
        self.datadir = os.path.join(self.currentdir, 'data')
        self.actions_dir = os.path.join(self.currentdir, 'actions')
        self.webdir = os.path.join(self.currentdir, 'web')
        self.resourcesdir = os.path.join(self.currentdir, 'resources')
        self.backupbasedir = os.path.join(self.currentdir, 'backup')
        # Directories under backupbasedir
        self.backupdir = os.path.join(self.backupbasedir, 'backups')
        self.upload_dir = os.path.join(self.backupbasedir, 'uploads')

        # Directories under datadir
        self.logsdir = os.path.join(self.datadir, 'logs')
        self.output_dir = os.path.join(self.datadir, 'output')
        self.input_dir = os.path.join(self.datadir, 'input')
        # Directories under output_dir
        self.crackedpwddir = os.path.join(self.output_dir, 'crackedpwd')
        self.datastolendir = os.path.join(self.output_dir, 'data_stolen')
        self.zombiesdir = os.path.join(self.output_dir, 'zombies')
        self.vulnerabilities_dir = os.path.join(self.output_dir, 'vulnerabilities')
        self.scan_results_dir = os.path.join(self.output_dir, "scan_results")
        # Directories under resourcesdir
        self.picdir = os.path.join(self.resourcesdir, 'images')
        self.fontdir = os.path.join(self.resourcesdir, 'fonts')
        self.commentsdir = os.path.join(self.resourcesdir, 'comments')
        # Directories under picdir
        self.statuspicdir = os.path.join(self.picdir, 'status')
        self.staticpicdir = os.path.join(self.picdir, 'static')
        # Directory under input_dir
        self.dictionarydir = os.path.join(self.input_dir, "dictionary")
        """Files paths"""
        # Files directly under configdir
        self.shared_config_json = os.path.join(self.configdir, 'shared_config.json')
        self.actions_file = os.path.join(self.configdir, 'actions.json')
        # Files directly under resourcesdir
        self.commentsfile = os.path.join(self.commentsdir, 'comments.json')
        # Files directly under datadir
        self.netkbfile = os.path.join(self.datadir, "netkb.csv")
        self.livestatusfile = os.path.join(self.datadir, 'livestatus.csv')
        self.gamification_file = os.path.join(self.datadir, 'gamification.json')
        # Files directly under vulnerabilities_dir
        self.vuln_summary_file = os.path.join(self.vulnerabilities_dir, 'vulnerability_summary.csv')
        self.vuln_scan_progress_file = os.path.join(self.vulnerabilities_dir, 'scan_progress.json')
        # Files directly under dictionarydir
        self.usersfile = os.path.join(self.dictionarydir, "users.txt")
        self.passwordsfile = os.path.join(self.dictionarydir, "passwords.txt")
        # Files directly under crackedpwddir
        self.sshfile = os.path.join(self.crackedpwddir, 'ssh.csv')
        self.smbfile = os.path.join(self.crackedpwddir, "smb.csv")
        self.telnetfile = os.path.join(self.crackedpwddir, "telnet.csv")
        self.ftpfile = os.path.join(self.crackedpwddir, "ftp.csv")
        self.sqlfile = os.path.join(self.crackedpwddir, "sql.csv")
        self.rdpfile = os.path.join(self.crackedpwddir, "rdp.csv")
        #Files directly under logsdir
        self.webconsolelog = os.path.join(self.logsdir, 'temp_log.txt')

    def get_default_config(self):
        """ The configuration below is used to set the default values of the configuration settings."""
        """ It can be used to reset the configuration settings to their default values."""
        """ You can mofify the json file shared_config.json or on the web page to change the default values of the configuration settings."""
        return {
            "__title_Ragnar__": "Settings",
            "manual_mode": False,
            "websrv": True,
            "web_increment": False,
            "debug_mode": True,
            "scan_vuln_running": True,
            "scan_vuln_no_ports": True,
            "enable_attacks": True,
            "retry_success_actions": True,
            "retry_failed_actions": True,
            "blacklistcheck": True,
            "displaying_csv": True,
            "log_debug": True,
            "log_info": True,
            "log_warning": True,
            "log_error": True,
            "log_critical": True,
            "terminal_log_level": "all",
            
            "startup_delay": 10,
            "web_delay": 2,
            "screen_delay": 1,
            "comment_delaymin": 15,
            "comment_delaymax": 30,
            "livestatus_delay": 8,
            "image_display_delaymin": 2,
            "image_display_delaymax": 8,
            "scan_interval": 180,
            "scan_vuln_interval": 300,
            "failed_retry_delay": 180,
            "success_retry_delay": 300,
            "action_timeout": 300,
            "vuln_scan_timeout": 1800,
            "ref_width" :122 ,
            "ref_height" : 250,
            "epd_type": "epd2in13_V4",
            
            
            "__title_lists__": "List Settings",
            "portlist": [20, 21, 22, 23, 25, 53, 67, 68, 69, 80, 88, 110, 111, 119, 123, 135, 137, 138, 139, 143, 161, 162, 179, 389, 443, 445, 465, 514, 515, 520, 554, 587, 631, 636, 993, 995, 1024, 1025, 1080, 1194, 1433, 1434, 1521, 1723, 1812, 1813, 1883, 1900, 2049, 2082, 2083, 2181, 2375, 2376, 2483, 2484, 25565, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 4000, 5000, 5003, 5004, 5060, 5061, 5432, 5500, 5555, 5631, 5632, 5900, 5985, 5986, 6000, 6379, 6667, 6881, 6969, 7000, 7070, 8080, 8081, 8086, 8181, 8443, 8888, 9000, 9090, 9100, 9200, 9418, 9999, 10000],
            "mac_scan_blacklist": [],
            "ip_scan_blacklist": [],
            "steal_file_names": ["ssh.csv","hack.txt"],
            "steal_file_extensions": [".ragnar",".hack",".flag"],
            
            "__title_network__": "Network",
            "nmap_scan_aggressivity": "-T4",
            "portstart": 1,
            "portend": 5500,
            "default_vulnerability_ports": [22, 80, 443],
            "network_max_failed_pings": 15,
            "network_device_retention_days": 14,
            "network_device_retention_hours": 8,  # Legacy data cleanup after 8 hours
            "network_ping_grace_period_minutes": 30,
            
            "__title_timewaits__": "Time Wait Settings",
            "timewait_smb": 0,
            "timewait_ssh": 0,
            "timewait_telnet": 0,
            "timewait_ftp": 0,
            "timewait_sql": 0,
            "timewait_rdp": 0,
            
            "__title_wifi__": "Wi-Fi Management",
            "wifi_known_networks": [],
            "wifi_ap_ssid": "Ragnar",
            "wifi_ap_password": "ragnarconnect",
            "wifi_connection_timeout": 60,
            "wifi_max_attempts": 3,
            "wifi_scan_interval": 300,
            "wifi_monitor_enabled": True,
            "wifi_auto_ap_fallback": True,
            "wifi_ap_timeout": 180,
            "wifi_ap_idle_timeout": 180,
            "wifi_reconnect_interval": 20,
            "wifi_ap_cycle_enabled": True,
            "wifi_initial_connection_timeout": 60,
            "wifi_failsafe_cycle_limit": 10,

            "network_device_retention_days": 14,

            "__title_network_intelligence__": "Network Intelligence",
            "network_resolution_timeout": 3600,
            "network_confirmation_scans": 3,
            "network_change_grace": 300,
            "network_intelligence_enabled": True,
            "network_auto_resolution": True,
        }

    def _normalize_config_keys(self, config):
        """Ensure legacy or malformed configuration keys are aligned with the current schema."""
        if 'web_increment ' in config:
            if 'web_increment' not in config:
                config['web_increment'] = config['web_increment ']
            del config['web_increment ']
        return config

    def _remove_legacy_attributes(self):
        """Drop attributes created from legacy configuration keys that cannot be accessed normally."""
        legacy_attrs = ['web_increment ']
        for attr in legacy_attrs:
            if hasattr(self, attr):
                delattr(self, attr)

    def update_mac_blacklist(self):
        """Update the MAC blacklist without immediate save."""
        mac_address = self.get_raspberry_mac()
        if mac_address:
            if 'mac_scan_blacklist' not in self.config:
                self.config['mac_scan_blacklist'] = []
            
            if mac_address not in self.config['mac_scan_blacklist']:
                self.config['mac_scan_blacklist'].append(mac_address)
                logger.info(f"Added local MAC address {mac_address} to blacklist")
            else:
                logger.info(f"Local MAC address {mac_address} already in blacklist")
        else:
            logger.warning("Could not add local MAC to blacklist: MAC address not found")



    def get_raspberry_mac(self):
        """Get the MAC address of the primary network interface (usually wlan0 or eth0)."""
        try:
            # First try wlan0 (wireless interface)
            result = subprocess.run(['cat', '/sys/class/net/wlan0/address'], 
                                 capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip().lower()
            
            # If wlan0 fails, try eth0 (ethernet interface)
            result = subprocess.run(['cat', '/sys/class/net/eth0/address'], 
                                 capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip().lower()
            
            logger.warning("Could not find MAC address for wlan0 or eth0")
            return None
            
        except Exception as e:
            logger.error(f"Error getting Raspberry Pi MAC address: {e}")
            return None



    def setup_environment(self, clear_console=False):
        """Setup the environment with the necessary directories and files."""
        if clear_console:
            os.system('cls' if os.name == 'nt' else 'clear')
        self.create_directories()  # Create all necessary directories first
        self.save_config()
        self.generate_actions_json()
        self.delete_webconsolelog()
        self.initialize_csv()
        self.initialize_epd_display()
    
    def create_directories(self):
        """Create all necessary directories for the application."""
        directories_to_create = [
            self.configdir,
            self.datadir,
            self.actions_dir,
            self.webdir,
            self.resourcesdir,
            self.backupbasedir,
            self.backupdir,
            self.upload_dir,
            self.logsdir,
            self.output_dir,
            self.input_dir,
            self.crackedpwddir,
            self.datastolendir,
            self.zombiesdir,
            self.vulnerabilities_dir,
            self.scan_results_dir,
            self.picdir,
            self.fontdir,
            self.commentsdir,
            self.statuspicdir,
            self.staticpicdir,
            self.dictionarydir
        ]
        
        for directory in directories_to_create:
            try:
                if not os.path.exists(directory):
                    os.makedirs(directory, exist_ok=True)
                    logger.info(f"Created directory: {directory}")
            except Exception as e:
                logger.error(f"Failed to create directory {directory}: {e}")
    

    # def initialize_epd_display(self):
    #     """Initialize the e-paper display."""
    #     try:
    #         logger.info("Initializing EPD display...")
    #         time.sleep(1)
    #         self.epd_helper = EPDHelper(self.config["epd_type"])
    #         self.epd_helper = EPDHelper(self.epd_type)
    #         if self.config["epd_type"] == "epd2in13_V2":
    #             logger.info("EPD type: epd2in13_V2 screen reversed")
    #             self.screen_reversed = False
    #             self.web_screen_reversed = False
    #         elif self.config["epd_type"] == "epd2in13_V3":
    #             logger.info("EPD type: epd2in13_V3 screen reversed")
    #             self.screen_reversed = False
    #             self.web_screen_reversed = False
    #         elif self.config["epd_type"] == "epd2in13_V4":
    #             logger.info("EPD type: epd2in13_V4 screen reversed")
    #             self.screen_reversed = True
    #             self.web_screen_reversed = True
    #         self.epd_helper.init_full_update()
    #         self.width, self.height = self.epd_helper.epd.width, self.epd_helper.epd.height
    #         logger.info(f"EPD {self.config['epd_type']} initialized with size: {self.width}x{self.height}")
    #     except Exception as e:
    #         logger.error(f"Error initializing EPD display: {e}")
    #         raise
    def initialize_epd_display(self):
        """Initialize the e-paper display."""
        try:
            logger.info("Initializing EPD display...")
            time.sleep(1)
            self.epd_helper = EPDHelper(self.config["epd_type"])
            # self.epd_helper = EPDHelper(self.epd_type)  # FIXED: Commented out invalid duplicate initialization
            if self.config["epd_type"] == "epd2in7":
                logger.info("EPD type: epd2in7 screen reversed")
                self.screen_reversed = False
                self.web_screen_reversed = False
            elif self.config["epd_type"] == "epd2in13_V2":
                logger.info("EPD type: epd2in13_V2 screen reversed")
                self.screen_reversed = False
                self.web_screen_reversed = False
            elif self.config["epd_type"] == "epd2in13_V3":
                logger.info("EPD type: epd2in13_V3 screen reversed")
                self.screen_reversed = True
                self.web_screen_reversed = True
            elif self.config["epd_type"] == "epd2in13_V4":
                logger.info("EPD type: epd2in13_V4 screen normal (not reversed)")
                self.screen_reversed = False
                self.web_screen_reversed = False
            self.epd_helper.init_full_update()
            self.width, self.height = self.epd_helper.epd.width, self.epd_helper.epd.height
            logger.info(f"EPD {self.config['epd_type']} initialized with size: {self.width}x{self.height}")
        except Exception as e:
            logger.error(f"Error initializing EPD display: {e}")
            logger.warning("Continuing without EPD display support")
            # Set default values and continue without EPD
            self.epd_helper = None
            self.width = 122  # Default width from config
            self.height = 250  # Default height from config
            self.screen_reversed = False
            self.web_screen_reversed = False
            
            # NOTE: Test image code below was used to verify EPD hardware. 
            # Commented out to allow normal Ragnar display to show.
            # Uncomment if you need to test the display again.
            # from PIL import ImageDraw
            # test_image = Image.new('1', (self.width, self.height), 255)
            # draw = ImageDraw.Draw(test_image)
            # draw.text((10, 10), "EPD Test", fill=0)
            # if self.config.get("reversed", False):
            #     test_image = test_image.rotate(180)
            # self.epd_helper.epd.display(self.epd_helper.epd.getbuffer(test_image))
            # logger.info("Test image displayed on EPD.")
        except Exception as e:
            logger.error(f"Error initializing EPD display: {e}")
            raise
        
    def initialize_variables(self):
        """Initialize the variables."""
        self.should_exit = False
        self.display_should_exit = False
        self.orchestrator_should_exit = False
        self.webapp_should_exit = False 
        self.ragnar_instance = None
        self.wifichanged = False
        self.bluetooth_active = False
        self.bluetooth_scan_active = False
        self.bluetooth_scan_start_time = 0.0
        self.wifi_connected = False
        self.pan_connected = False
        self.usb_active = False
        self.ragnarsays = "Hacking away..."
        self.ragnarorch_status = "IDLE"
        self.ragnarstatustext = "IDLE"
        self.ragnarstatustext2 = "Awakening..."
        self.scale_factor_x = self.width / self.ref_width
        self.scale_factor_y = self.height / self.ref_height
        self.text_frame_top = int(88 * self.scale_factor_x)
        self.text_frame_bottom = int(159 * self.scale_factor_y)
        self.y_text = self.text_frame_top + 2
        self.targetnbr = 0
        self.portnbr = 0
        self.vulnnbr = 0
        self.crednbr = 0
        self.datanbr = 0
        self.zombiesnbr = 0
        self.coinnbr = 0
        self.levelnbr = 0
        self.networkkbnbr = 0
        self.attacksnbr = 0
        self.vulnerable_host_count = 0
        self.gamification_data = {}
        self.points_per_level = 200
        self.points_per_mac = 15
        self.points_per_credential = 25
        self.points_per_data_file = 10
        self.points_per_zombie = 40
        self.points_per_vulnerability = 20
        self.show_first_image = True
        self.network_hosts_snapshot = {}
        self.total_targetnbr = 0
        self.inactive_targetnbr = 0
        self.new_targets = 0
        self.lost_targets = 0
        self.new_target_ips = []
        self.lost_target_ips = []
        self.last_sync_timestamp = 0.0
        self.imagegen = None  # Initialize imagegen variable
        self.x_center = 0  # Initialize x_center for image positioning
        self.y_bottom = 0  # Initialize y_bottom for image positioning
        self.x_center1 = 0  # Alternative positioning
        self.y_bottom1 = 0  # Alternative positioning
        
        # In-memory scan results for immediate orchestrator access
        # Stores latest live hosts from scanner without waiting for CSV writes
        self.latest_scan_results = None  # List of host dicts with 'MAC Address', 'IPs', 'Hostnames', 'Alive', 'Ports', etc.
        self.latest_scan_timestamp = 0.0  # Time when last scan completed
        self._scan_results_lock = threading.Lock()  # Thread-safe access to scan results

    def load_gamification_data(self):
        """Load persistent gamification progress from disk."""
        os.makedirs(self.datadir, exist_ok=True)

        default_data = {
            "version": 1,
            "total_points": 0,
            "level": 1,
            "mac_points": {},
            "lifetime_counts": {}
        }

        loaded_data = {}
        if os.path.exists(self.gamification_file):
            try:
                with open(self.gamification_file, 'r', encoding='utf-8') as fp:
                    raw_data = json.load(fp)
                    if isinstance(raw_data, dict):
                        loaded_data = raw_data
            except json.JSONDecodeError:
                logger.warning("Gamification file is corrupted; starting with defaults")
            except Exception as exc:
                logger.warning(f"Unable to load gamification file: {exc}")

        self.gamification_data = {**default_data, **loaded_data}
        if not isinstance(self.gamification_data.get("mac_points"), dict):
            self.gamification_data["mac_points"] = {}
        if not isinstance(self.gamification_data.get("lifetime_counts"), dict):
            self.gamification_data["lifetime_counts"] = {}

        self._update_gamification_state()

    def save_gamification_data(self):
        """Persist gamification progress to disk."""
        try:
            os.makedirs(os.path.dirname(self.gamification_file), exist_ok=True)
            data_to_save = dict(self.gamification_data)
            data_to_save["total_points"] = int(self.gamification_data.get("total_points", 0) or 0)
            data_to_save["level"] = int(self.gamification_data.get("level", 1) or 1)
            with open(self.gamification_file, 'w', encoding='utf-8') as fp:
                json.dump(data_to_save, fp, indent=4)
        except Exception as exc:
            logger.error(f"Failed to save gamification data: {exc}")

    def calculate_level(self, total_points: int) -> int:
        """Calculate the level from total points using a slower progression curve."""
        if total_points < 0:
            total_points = 0
        return max(1, 1 + total_points // max(self.points_per_level, 1))

    def _update_gamification_state(self):
        """Synchronize in-memory level/points from gamification data."""
        total_points = int(self.gamification_data.get("total_points", 0) or 0)
        self.coinnbr = total_points
        self.levelnbr = self.calculate_level(total_points)
        self.gamification_data["level"] = self.levelnbr

    def normalize_mac(self, mac_address: str) -> str:
        """Return a normalized MAC address suitable for persistence."""
        if not mac_address:
            return ""

        mac = mac_address.strip().upper()
        if mac in {"UNKNOWN", "N/A", "NONE"}:
            return ""

        mac = mac.replace('-', ':')
        if '.' in mac:
            mac = mac.replace('.', '')
        mac = mac.replace(' ', '')

        if ':' not in mac and len(mac) == 12:
            mac = ':'.join(mac[i:i + 2] for i in range(0, 12, 2))

        if mac.count(':') == 5:
            if mac in {"00:00:00:00:00:00", "FF:FF:FF:FF:FF:FF"}:
                return ""
            return mac

        return ""

    def process_discovered_macs(self, mac_addresses):
        """Track newly discovered MAC addresses and award points once per device."""
        normalized = {self.normalize_mac(mac) for mac in mac_addresses}
        normalized.discard("")

        if not normalized:
            return 0, 0

        with self._stats_lock:
            mac_points = self.gamification_data.setdefault("mac_points", {})
            new_mac_count = 0
            points_awarded = 0

            for mac in normalized:
                if mac in mac_points:
                    continue
                mac_points[mac] = {
                    "points": self.points_per_mac,
                    "first_seen": datetime.utcnow().isoformat() + "Z"
                }
                new_mac_count += 1
                points_awarded += self.points_per_mac

            if points_awarded:
                previous_points = self.gamification_data.get("total_points", 0)
                self.gamification_data["total_points"] = int(previous_points) + points_awarded
                prev_level = self.levelnbr
                self._update_gamification_state()
                self.save_gamification_data()
                logger.info(
                    f"Awarded {points_awarded} points for {new_mac_count} new MAC address(es). "
                    f"Level {prev_level} -> {self.levelnbr}"
                )

            return new_mac_count, points_awarded

    def delete_webconsolelog(self):
            """Delete the web console log file."""
            try:
                if os.path.exists(self.webconsolelog):
                    os.remove(self.webconsolelog)
                    logger.info(f"Deleted web console log file at {self.webconsolelog}")
                    #recreate the file

                else:
                    logger.info(f"Web console log file not found at {self.webconsolelog} ...")

            except OSError as e:
                logger.error(f"OS error occurred while deleting web console log file: {e}")
            except Exception as e:
                logger.error(f"Unexpected error occurred while deleting web console log file: {e}")

    def create_livestatusfile(self):
        """Create the live status file, it will be used to store the current status of the scan."""
        try:
            if not os.path.exists(self.livestatusfile):
                with open(self.livestatusfile, 'w', newline='') as csvfile:
                    csvwriter = csv.writer(csvfile)
                    csvwriter.writerow(['Total Open Ports', 'Alive Hosts Count', 'All Known Hosts Count', 'Vulnerabilities Count'])
                    csvwriter.writerow([0, 0, 0, 0])
                logger.info(f"Created live status file at {self.livestatusfile}")
            else:
                logger.info(f"Live status file already exists at {self.livestatusfile}")
        except OSError as e:
            logger.error(f"OS error occurred while creating live status file: {e}")
        except Exception as e:
            logger.error(f"Unexpected error occurred while creating live status file: {e}")


    def generate_actions_json(self):
        """Generate the actions JSON file, it will be used to store the actions configuration."""
        actions_dir = self.actions_dir
        actions_config = []
        try:
            for filename in os.listdir(actions_dir):
                if filename.endswith('.py') and filename != '__init__.py':
                    module_name = filename[:-3]
                    try:
                        module = importlib.import_module(f'actions.{module_name}')
                        b_class = getattr(module, 'b_class')
                        b_status = getattr(module, 'b_status')
                        b_port = getattr(module, 'b_port', None)
                        b_parent = getattr(module, 'b_parent', None)
                        actions_config.append({
                            "b_module": module_name,
                            "b_class": b_class,
                            "b_port": b_port,
                            "b_status": b_status,
                            "b_parent": b_parent
                        })
                        #add each b_class to the status list
                        self.status_list.append(b_class)
                    except AttributeError as e:
                        logger.error(f"Module {module_name} is missing required attributes: {e}")
                    except ImportError as e:
                        logger.error(f"Error importing module {module_name}: {e}")
                    except Exception as e:
                        logger.error(f"Unexpected error while processing module {module_name}: {e}")
            
            try:
                with open(self.actions_file, 'w') as file:
                    json.dump(actions_config, file, indent=4)
            except IOError as e:
                logger.error(f"Error writing to file {self.actions_file}: {e}")
            except Exception as e:
                logger.error(f"Unexpected error while writing to file {self.actions_file}: {e}")
        except Exception as e:
            logger.error(f"Unexpected error in generate_actions_json: {e}")


    def initialize_csv(self):
        """Initialize the network knowledge base CSV file with headers."""
        logger.info("Initializing the network knowledge base CSV file with headers")
        try:
            if not os.path.exists(self.netkbfile):
                try:
                    with open(self.actions_file, 'r') as file:
                        actions = json.load(file)
                    action_names = [action["b_class"] for action in actions if "b_class" in action]
                except FileNotFoundError as e:
                    logger.error(f"Actions file not found: {e}")
                    return
                except json.JSONDecodeError as e:
                    logger.error(f"Error decoding JSON from actions file: {e}")
                    return
                except Exception as e:
                    logger.error(f"Unexpected error reading actions file: {e}")
                    return

                headers = ["MAC Address", "IPs", "Hostnames", "Alive", "Ports", "Failed_Pings"] + action_names

                try:
                    with open(self.netkbfile, 'w', newline='') as file:
                        writer = csv.writer(file)
                        writer.writerow(headers)
                    logger.info(f"Network knowledge base CSV file created at {self.netkbfile}")
                except IOError as e:
                    logger.error(f"Error writing to netkbfile: {e}")
                except Exception as e:
                    logger.error(f"Unexpected error while writing to netkbfile: {e}")
            else:
                logger.info(f"Network knowledge base CSV file already exists at {self.netkbfile}")
        except Exception as e:
            logger.error(f"Unexpected error in initialize_csv: {e}")


    def load_config(self):
        """Load the configuration from the shared configuration JSON file."""
        try:
            logger.info("Loading configuration...")
            if os.path.exists(self.shared_config_json):
                with open(self.shared_config_json, 'r') as f:
                    config = json.load(f)
                    config = self._normalize_config_keys(config)
                    self.config.update(config)
                    self.config = self._normalize_config_keys(self.config)
                    for key, value in self.config.items():
                        setattr(self, key, value)
                    self._remove_legacy_attributes()
            else:
                logger.warning("Configuration file not found, creating new one with default values...")
                self.save_config()
                self.load_config()
                time.sleep(2)
        except FileNotFoundError:
            logger.error("Error loading configuration: File not found.")
            self.save_config()

    def save_config(self):
        """Save the configuration to the shared configuration JSON file."""
        logger.info("Saving configuration...")
        try:
            if not os.path.exists(self.configdir):
                os.makedirs(self.configdir)
                logger.info(f"Created configuration directory at {self.configdir}")
            try:
                self.config = self._normalize_config_keys(self.config)
                with open(self.shared_config_json, 'w') as f:
                    json.dump(self.config, f, indent=4)
                logger.info(f"Configuration saved to {self.shared_config_json}")
            except IOError as e:
                logger.error(f"Error writing to configuration file: {e}")
            except Exception as e:
                logger.error(f"Unexpected error while writing to configuration file: {e}")
        except OSError as e:
            logger.error(f"OS error while creating configuration directory: {e}")
        except Exception as e:
            logger.error(f"Unexpected error in save_config: {e}")

    def load_fonts(self):
        """Load the fonts."""
        try:
            logger.info("Loading fonts...")
            self.font_arial14 = self.load_font('Arial.ttf', 14)
            self.font_arial11 = self.load_font('Arial.ttf', 11)
            self.font_arial9 = self.load_font('Arial.ttf', 9)
            self.font_arialbold = self.load_font('Arial.ttf', 12)
            self.font_viking = self.load_font('Viking.TTF', 13)

        except Exception as e:
            logger.error(f"Error loading fonts: {e}")
            raise

    def load_font(self, font_name, size):
        """Load a font."""
        try:
            return ImageFont.truetype(os.path.join(self.fontdir, font_name), size)
        except Exception as e:
            logger.error(f"Error loading font {font_name}: {e}")
            raise

    def load_images(self):
        """Load the images for the e-paper display."""
        try:
            logger.info("Loading images...")

            # Load static images from the root of staticpicdir
            self.ragnarstatusimage = None
            self.ragnar1 = self.load_image(os.path.join(self.staticpicdir, 'ragnar1.bmp')) # Used to calculate the center of the screen
            self.port = self.load_image(os.path.join(self.staticpicdir, 'port.bmp'))
            self.frise = self.load_image(os.path.join(self.staticpicdir, 'frise.bmp'))
            self.target = self.load_image(os.path.join(self.staticpicdir, 'target.bmp'))
            self.vuln = self.load_image(os.path.join(self.staticpicdir, 'vuln.bmp'))
            self.connected = self.load_image(os.path.join(self.staticpicdir, 'connected.bmp'))
            self.bluetooth = self.load_image(os.path.join(self.staticpicdir, 'bluetooth.bmp'))
            self.wifi = self.load_image(os.path.join(self.staticpicdir, 'wifi.bmp'))
            self.ethernet = self.load_image(os.path.join(self.staticpicdir, 'ethernet.bmp'))
            self.usb = self.load_image(os.path.join(self.staticpicdir, 'usb.bmp'))
            self.level = self.load_image(os.path.join(self.staticpicdir, 'level.bmp'))
            self.cred = self.load_image(os.path.join(self.staticpicdir, 'cred.bmp'))
            self.attack = self.load_image(os.path.join(self.staticpicdir, 'attack.bmp'))
            self.attacks = self.load_image(os.path.join(self.staticpicdir, 'attacks.bmp'))
            self.gold = self.load_image(os.path.join(self.staticpicdir, 'gold.bmp'))
            self.networkkb = self.load_image(os.path.join(self.staticpicdir, 'networkkb.bmp'))
            self.zombie = self.load_image(os.path.join(self.staticpicdir, 'zombie.bmp'))
            self.data = self.load_image(os.path.join(self.staticpicdir, 'data.bmp'))
            self.money = self.load_image(os.path.join(self.staticpicdir, 'money.bmp'))
            self.zombie_status = self.load_image(os.path.join(self.staticpicdir, 'zombie.bmp'))
            self.attack = self.load_image(os.path.join(self.staticpicdir, 'attack.bmp'))

            """ Load the images for the different actions status"""
            # Dynamically load status images based on actions.json
            try:
                with open(self.actions_file, 'r') as f:
                    actions = json.load(f)
                    for action in actions:
                        b_class = action.get('b_class')
                        if b_class:
                            indiv_status_path = os.path.join(self.statuspicdir, b_class)
                            image_path = os.path.join(indiv_status_path, f'{b_class}.bmp')
                            image = self.load_image(image_path)
                            setattr(self, b_class, image)
                            logger.info(f"Loaded image for {b_class} from {image_path}")
            except Exception as e:
                logger.error(f"Error loading images from actions file: {e}")

            # Load image series dynamically from subdirectories
            self.image_series = {}
            for status in self.status_list:
                self.image_series[status] = []
                status_dir = os.path.join(self.statuspicdir, status)
                if not os.path.isdir(status_dir):
                    os.makedirs(status_dir)
                    logger.warning(f"Directory {status_dir} did not exist and was created.")
                    logger.warning(f" {status} wil use the IDLE images till you add some images in the {status} folder")

                for image_name in os.listdir(status_dir):
                    if image_name.endswith('.bmp') and re.search(r'\d', image_name):
                        image = self.load_image(os.path.join(status_dir, image_name))
                        if image:
                            self.image_series[status].append(image)

            if not self.image_series:
                logger.error("No images loaded.")
            else:
                for status, images in self.image_series.items():
                    logger.info(f"Loaded {len(images)} images for status {status}.")


            """Calculate the position of the Ragnar image on the screen to center it"""
            if self.ragnar1 is not None:
                self.x_center1 = (self.width - self.ragnar1.width) // 2
                self.y_bottom1 = self.height - self.ragnar1.height
            else:
                logger.warning("ragnar1.bmp image not found, using default positioning")
                self.x_center1 = self.width // 2  # Center horizontally
                self.y_bottom1 = self.height - 20  # Default bottom position

        except Exception as e:
            logger.error(f"Error loading images: {e}")
            raise

    def update_ragnarstatus(self):
        """ Using getattr to obtain the reference of the attribute with the name stored in self.ragnarorch_status"""
        try:
            self.ragnarstatusimage = getattr(self, self.ragnarorch_status)
            if self.ragnarstatusimage is None:
                raise AttributeError
        except AttributeError:
            logger.warning(f"The image for status {self.ragnarorch_status} is not available, using IDLE image by default.")
            self.ragnarstatusimage = self.attack
        
        self.ragnarstatustext = self.ragnarorch_status  # Mettre Ã  jour le texte du statut


    def load_image(self, image_path):

        """Load an image."""
        try:
            if not os.path.exists(image_path):
                logger.warning(f"Warning: {image_path} does not exist.")
                return None
            return Image.open(image_path)
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {e}")
            raise

    def update_image_randomizer(self):
        """Update the image randomizer and the imagegen variable."""
        try:
            status = self.ragnarstatustext
            if status in self.image_series and self.image_series[status]:
                random_index = random.randint(0, len(self.image_series[status]) - 1)
                self.imagegen = self.image_series[status][random_index]
                self.x_center = (self.width - self.imagegen.width) // 2
                self.y_bottom = self.height - self.imagegen.height
            else:
                logger.warning(f"Warning: No images available for status {status}, defaulting to IDLE images.")
                if "IDLE" in self.image_series and self.image_series["IDLE"]:
                    random_index = random.randint(0, len(self.image_series["IDLE"]) - 1)
                    self.imagegen = self.image_series["IDLE"][random_index]
                    self.x_center = (self.width - self.imagegen.width) // 2
                    self.y_bottom = self.height - self.imagegen.height
                else:
                    logger.error("No IDLE images available either.")
                    self.imagegen = None
        except Exception as e:
            logger.error(f"Error updating image randomizer: {e}")
            self.imagegen = None

    def wrap_text(self, text, font, max_width):
        """Wrap text to fit within a specified width when rendered."""
        try:
            lines = []
            words = text.split()
            while words:
                line = ''
                while words and font.getlength(line + words[0]) <= max_width:
                    line = line + (words.pop(0) + ' ')
                lines.append(line)
            return lines
        except Exception as e:
            logger.error(f"Error wrapping text: {e}")
            raise


    def set_latest_scan_results(self, scan_data):
        """Store fresh scan results in memory for immediate orchestrator access.
        
        Args:
            scan_data: List of dictionaries with keys: 'MAC Address', 'IPs', 'Hostnames', 'Alive', 'Ports', etc.
        """
        with self._scan_results_lock:
            self.latest_scan_results = scan_data
            self.latest_scan_timestamp = time.time()
            logger.info(f"ðŸ“‹ Stored {len(scan_data)} live hosts in memory for immediate orchestrator access")
    
    def get_latest_scan_results(self):
        """Retrieve fresh scan results from memory if available.
        
        Returns:
            List of host dictionaries if available, None otherwise
        """
        with self._scan_results_lock:
            if self.latest_scan_results is not None:
                age_seconds = time.time() - self.latest_scan_timestamp
                logger.info(f"ðŸ“‹ Retrieved {len(self.latest_scan_results)} hosts from memory (age: {age_seconds:.1f}s)")
            return self.latest_scan_results
    
    def read_data(self):
        """Read data from the CSV file with robust error handling."""
        self.initialize_csv()  # Ensure CSV is initialized with correct headers
        data = []
        try:
            with open(self.netkbfile, 'r', newline='', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                expected_fieldnames = reader.fieldnames
                
                for line_num, row in enumerate(reader, start=2):  # Start at 2 (after header)
                    try:
                        # Check if row has extra fields (malformed)
                        if len(row) > len(expected_fieldnames) if expected_fieldnames else False:
                            logger.warning(f"Skipping malformed row {line_num} in netkb.csv: too many fields")
                            continue
                        
                        # Only add rows with valid MAC address
                        if row.get("MAC Address") and row["MAC Address"].strip():
                            data.append(row)
                    except Exception as row_error:
                        logger.warning(f"Error reading row {line_num} in netkb.csv: {row_error}")
                        continue
                        
        except Exception as e:
            logger.error(f"Error reading netkb.csv: {e}")
            # If file is corrupted, try to restore from backup
            backup_file = f"{self.netkbfile}.backup"
            if os.path.exists(backup_file):
                logger.info(f"Attempting to restore from backup: {backup_file}")
                try:
                    import shutil
                    shutil.copy2(backup_file, self.netkbfile)
                    return self.read_data()  # Retry reading
                except Exception as restore_error:
                    logger.error(f"Could not restore from backup: {restore_error}")
        
        return data

    def write_data(self, data):
        """Write data to the CSV file."""
        with open(self.actions_file, 'r') as file:
            actions = json.load(file)
        action_names = [action["b_class"] for action in actions if "b_class" in action]

        # Read existing CSV file if it exists with error handling
        existing_headers = []
        existing_data = []
        
        if os.path.exists(self.netkbfile):
            try:
                with open(self.netkbfile, 'r', newline='', encoding='utf-8') as file:
                    reader = csv.DictReader(file)
                    existing_headers = list(reader.fieldnames) if reader.fieldnames else []
                    
                    for line_num, row in enumerate(reader, start=2):
                        try:
                            # Skip malformed rows
                            if len(row) > len(existing_headers) if existing_headers else False:
                                logger.warning(f"Skipping malformed row {line_num} during write_data")
                                continue
                            existing_data.append(row)
                        except Exception as row_error:
                            logger.warning(f"Error reading row {line_num}: {row_error}")
                            continue
                            
            except Exception as read_error:
                logger.error(f"Error reading netkbfile for write_data: {read_error}")
                # Try backup if available
                backup_file = f"{self.netkbfile}.backup"
                if os.path.exists(backup_file):
                    logger.info("Attempting to restore from backup before write")
                    try:
                        import shutil
                        shutil.copy2(backup_file, self.netkbfile)
                        # Retry read
                        with open(self.netkbfile, 'r', newline='', encoding='utf-8') as file:
                            reader = csv.DictReader(file)
                            existing_headers = list(reader.fieldnames) if reader.fieldnames else []
                            existing_data = list(reader)
                    except Exception as restore_error:
                        logger.error(f"Could not restore from backup: {restore_error}")

        # Check for missing action columns and add them
        new_headers = ["MAC Address", "IPs", "Hostnames", "Alive", "Ports", "Failed_Pings"] + action_names
        missing_headers = [header for header in new_headers if header not in existing_headers]

        # Update headers
        headers = existing_headers + missing_headers

        # Merge new data with existing data
        mac_to_existing_row = {row["MAC Address"]: row for row in existing_data}

        for new_row in data:
            mac_address = new_row["MAC Address"]
            if mac_address in mac_to_existing_row:
                # Update the existing row with new data
                existing_row = mac_to_existing_row[mac_address]
                for key, value in new_row.items():
                    if value:
                        existing_row[key] = value
            else:
                # Add new row
                mac_to_existing_row[mac_address] = new_row

        # Write updated data back to CSV with backup protection
        import tempfile
        import shutil
        
        # Only write if we have data to write
        if not mac_to_existing_row:
            self.print("Warning: No data to write to netkb.csv - skipping write")
            return
        
        # Create backup of existing file if it exists and has content
        if os.path.exists(self.netkbfile) and os.path.getsize(self.netkbfile) > 100:
            backup_file = f"{self.netkbfile}.backup"
            try:
                shutil.copy2(self.netkbfile, backup_file)
                self.print(f"Created backup: {backup_file}")
            except Exception as backup_error:
                logger.warning(f"Could not create backup: {backup_error}")
        
        # Write to temporary file first (atomic operation)
        temp_fd, temp_path = tempfile.mkstemp(dir=os.path.dirname(self.netkbfile), suffix='.tmp')
        try:
            with os.fdopen(temp_fd, 'w', newline='') as file:
                writer = csv.DictWriter(file, fieldnames=headers)
                writer.writeheader()
                
                # Write all data
                for row in mac_to_existing_row.values():
                    writer.writerow(row)
            
            # Verify temp file has content before replacing original
            if os.path.getsize(temp_path) > 50:  # At least headers
                shutil.move(temp_path, self.netkbfile)
                self.print(f"Successfully wrote {len(mac_to_existing_row)} entries to netkb.csv")
            else:
                logger.error("Temp file is too small - aborting write to prevent data loss")
                os.unlink(temp_path)
        except Exception as write_error:
            logger.error(f"Error writing netkb.csv: {write_error}")
            if os.path.exists(temp_path):
                os.unlink(temp_path)
            raise

    def update_stats(self, persist=True):
        """Update gamification stats using lifetime achievements rather than volatile counts."""
        with self._stats_lock:
            lifetime_counts = self.gamification_data.setdefault("lifetime_counts", {})
            total_added = 0
            awarded_breakdown = {}

            metrics = {
                "crednbr": (int(self.crednbr or 0), self.points_per_credential),
                "datanbr": (int(self.datanbr or 0), self.points_per_data_file),
                "zombiesnbr": (int(self.zombiesnbr or 0), self.points_per_zombie),
                "vulnnbr": (int(self.vulnnbr or 0), self.points_per_vulnerability),
            }

            for key, (current_value, points_value) in metrics.items():
                recorded_value = int(lifetime_counts.get(key, 0) or 0)
                if current_value > recorded_value:
                    delta = current_value - recorded_value
                    lifetime_counts[key] = current_value
                    points_gained = delta * points_value
                    total_added += points_gained
                    awarded_breakdown[key] = {
                        "delta": delta,
                        "points": points_gained
                    }
                else:
                    lifetime_counts[key] = max(recorded_value, current_value)

            if total_added:
                self.gamification_data["total_points"] = int(self.gamification_data.get("total_points", 0)) + total_added
                logger.info(f"Awarded {total_added} points from new achievements: {awarded_breakdown}")

            previous_points = self.coinnbr
            previous_level = self.levelnbr
            self._update_gamification_state()

            if persist and (total_added or self.coinnbr != previous_points or self.levelnbr != previous_level):
                self.save_gamification_data()

            return total_added


    def print(self, message):
        """Print a debug message if debug mode is enabled."""
        if self.config['debug_mode']:
            logger.debug(message)
