#shared.py
# Description:
# This file, shared.py, is a core component responsible for managing shared resources and data for different modules in the Ragnar project.
# It handles the initialization and configuration of paths, logging, fonts, and images. Additionally, it sets up the environment, 
# creates necessary directories and files, and manages the loading and saving of configuration settings.
# 
# Key functionalities include:
# - Initializing various paths used by the application, including directories for configuration, data, actions, web resources, and logs.
# - Setting up the environment, including the e-paper display, network knowledge base, and actions JSON configuration.
# - Loading and managing fonts and images required for the application's display.
# - Handling the creation and management of a live status file to store the current status of network scans.
# - Managing configuration settings, including loading default settings, updating, and saving configurations to a JSON file.
# - Providing utility functions for reading and writing data to CSV files, updating statistics, and wrapping text for display purposes.

import os
import re
import json
import importlib
import random
import time
import csv
import logging
import subprocess
import threading
import traceback
from datetime import datetime
from PIL import Image, ImageFont 
from logger import Logger
from epd_helper import EPDHelper
from db_manager import get_db


logger = Logger(name="shared.py", level=logging.DEBUG) # Create a logger object 

class SharedData:
    """Shared data between the different modules."""
    def __init__(self):
        self.initialize_paths() # Initialize the paths used by the application
        self.status_list = [] 
        self.last_comment_time = time.time() # Last time a comment was displayed
        self._stats_lock = threading.Lock()  # Thread-safe lock for update_stats()
        self.default_config = self.get_default_config() # Default configuration of the application  
        self.config = self.default_config.copy() # Configuration of the application
        # Load existing configuration first
        self.load_config()
        self._ensure_display_orientation_defaults()

        # Initialize SQLite database manager
        self.db = get_db(currentdir=self.currentdir)
        
        # Update MAC blacklist without immediate save
        self.update_mac_blacklist()
        self.setup_environment(clear_console=False) # Setup the environment without clearing console
        self.initialize_variables() # Initialize the variables used by the application
        self.load_gamification_data()  # Load persistent gamification progress

        # Initialize network intelligence (after paths and config are ready)
        self.network_intelligence = None
        self.initialize_network_intelligence()
        
        # Initialize AI service (after paths and config are ready)
        self.ai_service = None
        self.initialize_ai_service()
        
        self.create_livestatusfile() 
        self.load_fonts() # Load the fonts used by the application
        self.load_images() # Load the images used by the application
        # self.create_initial_image() # Create the initial image displayed on the screen
        
        # Start background cleanup task for old hosts
        self._start_cleanup_task()
        
    def initialize_network_intelligence(self):
        """Initialize the network intelligence system"""
        try:
            from network_intelligence import NetworkIntelligence
            self.network_intelligence = NetworkIntelligence(self)
            logger.info("Network intelligence system initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize network intelligence: {e}")
            self.network_intelligence = None
    
    def initialize_ai_service(self):
        """Initialize the AI service"""
        try:
            from ai_service import AIService
            logger.info("Attempting to initialize AI service...")
            self.ai_service = AIService(self)
            if self.ai_service.is_enabled():
                logger.info("AI service initialized successfully with GPT-5 Nano")
            else:
                init_error = getattr(self.ai_service, 'initialization_error', None)
                if init_error:
                    logger.warning(f"AI service initialized but not enabled: {init_error}")
                else:
                    logger.info("AI service initialized but not enabled (check configuration)")
        except ImportError as e:
            logger.error(f"Failed to import AI service module: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.ai_service = None
        except Exception as e:
            logger.error(f"Failed to initialize AI service: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.ai_service = None

    def initialize_paths(self):
        """Initialize the paths used by the application."""
        """Folders paths"""
        self.currentdir = os.path.dirname(os.path.abspath(__file__))
        # Directories directly under currentdir
        self.configdir = os.path.join(self.currentdir, 'config')
        self.datadir = os.path.join(self.currentdir, 'data')
        self.actions_dir = os.path.join(self.currentdir, 'actions')
        self.webdir = os.path.join(self.currentdir, 'web')
        self.resourcesdir = os.path.join(self.currentdir, 'resources')
        self.backupbasedir = os.path.join(self.currentdir, 'backup')
        # Directories under backupbasedir
        self.backupdir = os.path.join(self.backupbasedir, 'backups')
        self.upload_dir = os.path.join(self.backupbasedir, 'uploads')

        # Directories under datadir
        self.logsdir = os.path.join(self.datadir, 'logs')
        self.output_dir = os.path.join(self.datadir, 'output')
        self.input_dir = os.path.join(self.datadir, 'input')
        # Directories under output_dir
        self.crackedpwddir = os.path.join(self.output_dir, 'crackedpwd')
        self.datastolendir = os.path.join(self.output_dir, 'data_stolen')
        self.zombiesdir = os.path.join(self.output_dir, 'zombies')
        self.vulnerabilities_dir = os.path.join(self.output_dir, 'vulnerabilities')
        self.scan_results_dir = os.path.join(self.output_dir, "scan_results")
        # Directories under resourcesdir
        self.picdir = os.path.join(self.resourcesdir, 'images')
        self.fontdir = os.path.join(self.resourcesdir, 'fonts')
        self.commentsdir = os.path.join(self.resourcesdir, 'comments')
        # Directories under picdir
        self.statuspicdir = os.path.join(self.picdir, 'status')
        self.staticpicdir = os.path.join(self.picdir, 'static')
        # Directory under input_dir
        self.dictionarydir = os.path.join(self.input_dir, "dictionary")
        """Files paths"""
        # Files directly under configdir
        self.shared_config_json = os.path.join(self.configdir, 'shared_config.json')
        self.actions_file = os.path.join(self.configdir, 'actions.json')
        # Files directly under resourcesdir
        self.commentsfile = os.path.join(self.commentsdir, 'comments.json')
        # Files directly under datadir
        self.netkbfile = os.path.join(self.datadir, "netkb.csv")
        self.livestatusfile = os.path.join(self.datadir, 'livestatus.csv')
        self.gamification_file = os.path.join(self.datadir, 'gamification.json')
        # Files directly under vulnerabilities_dir
        self.vuln_summary_file = os.path.join(self.vulnerabilities_dir, 'vulnerability_summary.csv')
        self.vuln_scan_progress_file = os.path.join(self.vulnerabilities_dir, 'scan_progress.json')
        # Files directly under dictionarydir
        self.usersfile = os.path.join(self.dictionarydir, "users.txt")
        self.passwordsfile = os.path.join(self.dictionarydir, "passwords.txt")
        # Files directly under crackedpwddir
        self.sshfile = os.path.join(self.crackedpwddir, 'ssh.csv')
        self.smbfile = os.path.join(self.crackedpwddir, "smb.csv")
        self.telnetfile = os.path.join(self.crackedpwddir, "telnet.csv")
        self.ftpfile = os.path.join(self.crackedpwddir, "ftp.csv")
        self.sqlfile = os.path.join(self.crackedpwddir, "sql.csv")
        self.rdpfile = os.path.join(self.crackedpwddir, "rdp.csv")
        #Files directly under logsdir
        self.webconsolelog = os.path.join(self.logsdir, 'temp_log.txt')

    def get_default_config(self):
        """ The configuration below is used to set the default values of the configuration settings."""
        """ It can be used to reset the configuration settings to their default values."""
        """ You can mofify the json file shared_config.json or on the web page to change the default values of the configuration settings."""
        return {
            "__title_Ragnar__": "Settings",
            "manual_mode": False,
            "websrv": True,
            "web_increment": False,
            "debug_mode": True,
            "scan_vuln_running": True,
            "scan_vuln_no_ports": False,
            "enable_attacks": False,
            "retry_success_actions": True,
            "retry_failed_actions": True,
            "blacklistcheck": True,
            "displaying_csv": True,
            "log_debug": False,
            "log_info": True,
            "log_warning": True,
            "log_error": True,
            "log_critical": True,
            "terminal_log_level": "all",
            
            "startup_delay": 10,
            "web_delay": 2,
            "screen_delay": 1,
            "comment_delaymin": 15,
            "comment_delaymax": 30,
            "livestatus_delay": 8,
            "image_display_delaymin": 2,
            "image_display_delaymax": 8,
            "scan_interval": 180,
            "scan_vuln_interval": 300,
            "failed_retry_delay": 180,
            "success_retry_delay": 300,
            "action_timeout": 300,
            "vuln_scan_timeout": 1800,
            "ref_width" :122 ,
            "ref_height" : 250,
            "epd_type": "epd2in13_V4",
            
            
            "__title_lists__": "List Settings",
            "portlist": [20, 21, 22, 23, 25, 53, 67, 68, 69, 80, 88, 110, 111, 119, 123, 135, 137, 138, 139, 143, 161, 162, 179, 389, 443, 445, 465, 514, 515, 520, 554, 587, 631, 636, 993, 995, 1024, 1025, 1080, 1194, 1433, 1434, 1521, 1723, 1812, 1813, 1883, 1900, 2049, 2082, 2083, 2181, 2375, 2376, 2483, 2484, 25565, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 4000, 5000, 5003, 5004, 5060, 5061, 5432, 5500, 5555, 5631, 5632, 5900, 5985, 5986, 6000, 6379, 6667, 6881, 6969, 7000, 7070, 8080, 8081, 8086, 8181, 8443, 8888, 9000, 9090, 9100, 9200, 9418, 9999, 10000],
            "mac_scan_blacklist": [],
            "ip_scan_blacklist": [],
            "steal_file_names": ["ssh.csv","hack.txt","password","passwd","credential","key","secret","config","backup","settings","credentials","auth","environment","docker-compose","kubeconfig"],
            "steal_file_extensions": [".txt",".conf",".json",".xml",".db",".sql",".key",".pem",".crt",".log",".yaml",".yml",".config",".ini",".env",".cfg"],
            
            "__title_network__": "Network",
            "nmap_scan_aggressivity": "-T4",
            "portstart": 1,
            "portend": 5500,
            "default_vulnerability_ports": [22, 80, 443],
            "network_max_failed_pings": 15,
            "network_device_retention_days": 14,
            "network_device_retention_hours": 8,  # Legacy data cleanup after 8 hours
            "network_ping_grace_period_minutes": 30,
            
            "__title_timewaits__": "Time Wait Settings",
            "timewait_smb": 0,
            "timewait_ssh": 0,
            "timewait_telnet": 0,
            "timewait_ftp": 0,
            "timewait_sql": 0,
            "timewait_rdp": 0,
            
            "__title_wifi__": "Wi-Fi Management",
            "wifi_known_networks": [],
            "wifi_ap_ssid": "Ragnar",
            "wifi_ap_password": "ragnarconnect",
            "wifi_connection_timeout": 60,
            "wifi_max_attempts": 3,
            "wifi_scan_interval": 300,
            "wifi_monitor_enabled": True,
            "wifi_auto_ap_fallback": True,
            "wifi_ap_timeout": 180,
            "wifi_ap_idle_timeout": 180,
            "wifi_reconnect_interval": 20,
            "wifi_ap_cycle_enabled": True,
            "wifi_initial_connection_timeout": 60,
            "wifi_failsafe_cycle_limit": 10,

            "network_device_retention_days": 14,

            "__title_network_intelligence__": "Network Intelligence",
            "network_resolution_timeout": 3600,
            "network_confirmation_scans": 3,
            "network_change_grace": 300,
            "network_intelligence_enabled": True,
            "network_auto_resolution": True,

            "__title_ai__": "AI Integration (GPT-5 Nano)",
            "ai_enabled": False,
            "openai_api_token": "",
            "ai_model": "gpt-5-nano",
            "ai_analysis_enabled": True,
            "ai_vulnerability_summaries": True,
            "ai_network_insights": True,
            "ai_max_tokens": 500,
            "ai_temperature": 0.7,
        }

    def _normalize_config_keys(self, config):
        """Ensure legacy or malformed configuration keys are aligned with the current schema."""
        if 'web_increment ' in config:
            if 'web_increment' not in config:
                config['web_increment'] = config['web_increment ']
            del config['web_increment ']
        return config

    def _remove_legacy_attributes(self):
        """Drop attributes created from legacy configuration keys that cannot be accessed normally."""
        legacy_attrs = ['web_increment ']
        for attr in legacy_attrs:
            if hasattr(self, attr):
                delattr(self, attr)

    def update_mac_blacklist(self):
        """Update the MAC blacklist without immediate save."""
        mac_address = self.get_raspberry_mac()
        if mac_address:
            if 'mac_scan_blacklist' not in self.config:
                self.config['mac_scan_blacklist'] = []
            
            if mac_address not in self.config['mac_scan_blacklist']:
                self.config['mac_scan_blacklist'].append(mac_address)
                logger.info(f"Added local MAC address {mac_address} to blacklist")
            else:
                logger.info(f"Local MAC address {mac_address} already in blacklist")
        else:
            logger.warning("Could not add local MAC to blacklist: MAC address not found")



    def get_raspberry_mac(self):
        """Get the MAC address of the primary network interface (usually wlan0 or eth0)."""
        try:
            # First try wlan0 (wireless interface)
            result = subprocess.run(['cat', '/sys/class/net/wlan0/address'], 
                                 capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip().lower()
            
            # If wlan0 fails, try eth0 (ethernet interface)
            result = subprocess.run(['cat', '/sys/class/net/eth0/address'], 
                                 capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip().lower()
            
            logger.warning("Could not find MAC address for wlan0 or eth0")
            return None
            
        except Exception as e:
            logger.error(f"Error getting Raspberry Pi MAC address: {e}")
            return None



    def setup_environment(self, clear_console=False):
        """Setup the environment with the necessary directories and files."""
        if clear_console:
            os.system('cls' if os.name == 'nt' else 'clear')
        self.create_directories()  # Create all necessary directories first
        self.save_config()
        self.generate_actions_json()
        self.delete_webconsolelog()
        self.initialize_csv()
        self.initialize_epd_display()
    
    def create_directories(self):
        """Create all necessary directories for the application."""
        directories_to_create = [
            self.configdir,
            self.datadir,
            self.actions_dir,
            self.webdir,
            self.resourcesdir,
            self.backupbasedir,
            self.backupdir,
            self.upload_dir,
            self.logsdir,
            self.output_dir,
            self.input_dir,
            self.crackedpwddir,
            self.datastolendir,
            self.zombiesdir,
            self.vulnerabilities_dir,
            self.scan_results_dir,
            self.picdir,
            self.fontdir,
            self.commentsdir,
            self.statuspicdir,
            self.staticpicdir,
            self.dictionarydir
        ]
        
        for directory in directories_to_create:
            try:
                if not os.path.exists(directory):
                    os.makedirs(directory, exist_ok=True)
                    logger.info(f"Created directory: {directory}")
            except Exception as e:
                logger.error(f"Failed to create directory {directory}: {e}")
    

    # def initialize_epd_display(self):
    #     """Initialize the e-paper display."""
    #     try:
    #         logger.info("Initializing EPD display...")
    #         time.sleep(1)
    #         self.epd_helper = EPDHelper(self.config["epd_type"])
    #         self.epd_helper = EPDHelper(self.epd_type)
    #         if self.config["epd_type"] == "epd2in13_V2":
    #             logger.info("EPD type: epd2in13_V2 screen reversed")
    #             self.screen_reversed = False
    #             self.web_screen_reversed = False
    #         elif self.config["epd_type"] == "epd2in13_V3":
    #             logger.info("EPD type: epd2in13_V3 screen reversed")
    #             self.screen_reversed = False
    #             self.web_screen_reversed = False
    #         elif self.config["epd_type"] == "epd2in13_V4":
    #             logger.info("EPD type: epd2in13_V4 screen reversed")
    #             self.screen_reversed = True
    #             self.web_screen_reversed = True
    #         self.epd_helper.init_full_update()
    #         self.width, self.height = self.epd_helper.epd.width, self.epd_helper.epd.height
    #         logger.info(f"EPD {self.config['epd_type']} initialized with size: {self.width}x{self.height}")
    #     except Exception as e:
    #         logger.error(f"Error initializing EPD display: {e}")
    #         raise
    def _default_screen_orientation(self, epd_type):
        """Return whether the display should be rotated 180Â° by default for a given panel."""
        # Some Waveshare panels ship with connectors mounted upside down, so flipping keeps UX consistent.
        return epd_type in {"epd2in13_V3", "epd2in13_V4"}

    def _ensure_display_orientation_defaults(self):
        """Make sure configurable display orientation keys exist with sensible defaults."""
        epd_type = self.config.get("epd_type", "")
        default_flip = self._default_screen_orientation(epd_type)
        if 'screen_reversed' not in self.config:
            self.config['screen_reversed'] = default_flip
        # Keep web preview aligned with physical display unless overridden later.
        self.web_screen_reversed = self.config.get('web_screen_reversed', self.config['screen_reversed'])

    def initialize_epd_display(self):
        """Initialize the e-paper display."""
        try:
            logger.info("Initializing EPD display...")
            time.sleep(1)
            self.epd_helper = EPDHelper(self.config["epd_type"])
            # self.epd_helper = EPDHelper(self.epd_type)  # FIXED: Commented out invalid duplicate initialization
            epd_type = self.config["epd_type"]
            default_flip = self._default_screen_orientation(epd_type)
            flip_enabled = bool(self.config.get('screen_reversed', default_flip))
            self.config['screen_reversed'] = flip_enabled
            self.screen_reversed = flip_enabled
            self.web_screen_reversed = flip_enabled
            orientation_text = "reversed" if flip_enabled else "normal"
            logger.info(f"EPD type: {epd_type} screen {orientation_text} (configurable)")
            self.epd_helper.init_full_update()
            self.width, self.height = self.epd_helper.epd.width, self.epd_helper.epd.height
            logger.info(f"EPD {self.config['epd_type']} initialized with size: {self.width}x{self.height}")
        except Exception as e:
            logger.error(f"Error initializing EPD display: {e}")
            logger.warning("Continuing without EPD display support")
            # Set default values and continue without EPD
            self.epd_helper = None
            self.width = 122  # Default width from config
            self.height = 250  # Default height from config
            fallback_flip = bool(self.config.get('screen_reversed', False))
            self.screen_reversed = fallback_flip
            self.web_screen_reversed = fallback_flip
            
            # NOTE: Test image code below was used to verify EPD hardware. 
            # Commented out to allow normal Ragnar display to show.
            # Uncomment if you need to test the display again.
            # from PIL import ImageDraw
            # test_image = Image.new('1', (self.width, self.height), 255)
            # draw = ImageDraw.Draw(test_image)
            # draw.text((10, 10), "EPD Test", fill=0)
            # if self.config.get("reversed", False):
            #     test_image = test_image.rotate(180)
            # self.epd_helper.epd.display(self.epd_helper.epd.getbuffer(test_image))
            # logger.info("Test image displayed on EPD.")
        
    def initialize_variables(self):
        """Initialize the variables."""
        self.should_exit = False
        self.display_should_exit = False
        self.orchestrator_should_exit = False
        self.webapp_should_exit = False 
        self.ragnar_instance = None
        self.wifichanged = False
        self.bluetooth_active = False
        self.bluetooth_scan_active = False
        self.bluetooth_scan_start_time = 0.0
        self.wifi_connected = False
        self.pan_connected = False
        self.usb_active = False
        self.ragnarsays = "Hacking away..."
        self.ragnarorch_status = "IDLE"
        self.ragnarstatustext = "IDLE"
        self.ragnarstatustext2 = "Awakening..."
        self.scale_factor_x = self.width / self.config['ref_width']
        self.scale_factor_y = self.height / self.config['ref_height']
        self.text_frame_top = int(88 * self.scale_factor_x)
        self.text_frame_bottom = int(159 * self.scale_factor_y)
        self.y_text = self.text_frame_top + 2
        self.targetnbr = 0
        self.portnbr = 0
        self.vulnnbr = 0
        self.crednbr = 0
        self.datanbr = 0
        self.zombiesnbr = 0
        self.coinnbr = 0
        self.levelnbr = 0
        self.networkkbnbr = 0
        self.attacksnbr = 0
        self.vulnerable_host_count = 0
        self.gamification_data = {}
        self.points_per_level = 200
        self.points_per_mac = 15
        self.points_per_credential = 25
        self.points_per_data_file = 10
        self.points_per_zombie = 40
        self.points_per_vulnerability = 20
        self.show_first_image = True
        self.network_hosts_snapshot = {}
        self.total_targetnbr = 0
        self.inactive_targetnbr = 0
        self.new_targets = 0
        self.lost_targets = 0
        self.new_target_ips = []
        self.lost_target_ips = []
        self.last_sync_timestamp = 0.0
        self.imagegen = None  # Initialize imagegen variable
        self.x_center = 0  # Initialize x_center for image positioning
        self.y_bottom = 0  # Initialize y_bottom for image positioning
        self.x_center1 = 0  # Alternative positioning
        self.y_bottom1 = 0  # Alternative positioning
        
        # In-memory scan results for immediate orchestrator access
        # Stores latest live hosts from scanner without waiting for CSV writes
        self.latest_scan_results = None  # List of host dicts with 'MAC Address', 'IPs', 'Hostnames', 'Alive', 'Ports', etc.
        self.latest_scan_timestamp = 0.0  # Time when last scan completed
        self._scan_results_lock = threading.Lock()  # Thread-safe access to scan results

    def load_gamification_data(self):
        """Load persistent gamification progress from disk."""
        os.makedirs(self.datadir, exist_ok=True)

        default_data = {
            "version": 1,
            "total_points": 0,
            "level": 1,
            "mac_points": {},
            "lifetime_counts": {}
        }

        loaded_data = {}
        if os.path.exists(self.gamification_file):
            try:
                with open(self.gamification_file, 'r', encoding='utf-8') as fp:
                    raw_data = json.load(fp)
                    if isinstance(raw_data, dict):
                        loaded_data = raw_data
            except json.JSONDecodeError:
                logger.warning("Gamification file is corrupted; starting with defaults")
            except Exception as exc:
                logger.warning(f"Unable to load gamification file: {exc}")

        self.gamification_data = {**default_data, **loaded_data}
        if not isinstance(self.gamification_data.get("mac_points"), dict):
            self.gamification_data["mac_points"] = {}
        if not isinstance(self.gamification_data.get("lifetime_counts"), dict):
            self.gamification_data["lifetime_counts"] = {}

        self._update_gamification_state()

    def save_gamification_data(self):
        """Persist gamification progress to disk."""
        try:
            os.makedirs(os.path.dirname(self.gamification_file), exist_ok=True)
            data_to_save = dict(self.gamification_data)
            data_to_save["total_points"] = int(self.gamification_data.get("total_points", 0) or 0)
            data_to_save["level"] = int(self.gamification_data.get("level", 1) or 1)
            with open(self.gamification_file, 'w', encoding='utf-8') as fp:
                json.dump(data_to_save, fp, indent=4)
        except Exception as exc:
            logger.error(f"Failed to save gamification data: {exc}")

    def calculate_level(self, total_points: int) -> int:
        """Calculate the level from total points using a slower progression curve."""
        if total_points < 0:
            total_points = 0
        return max(1, 1 + total_points // max(self.points_per_level, 1))

    def _update_gamification_state(self):
        """Synchronize in-memory level/points from gamification data."""
        total_points = int(self.gamification_data.get("total_points", 0) or 0)
        self.coinnbr = total_points
        self.levelnbr = self.calculate_level(total_points)
        self.gamification_data["level"] = self.levelnbr

    def normalize_mac(self, mac_address: str) -> str:
        """Return a normalized MAC address suitable for persistence."""
        if not mac_address:
            return ""

        mac = mac_address.strip().upper()
        if mac in {"UNKNOWN", "N/A", "NONE"}:
            return ""

        mac = mac.replace('-', ':')
        if '.' in mac:
            mac = mac.replace('.', '')
        mac = mac.replace(' ', '')

        if ':' not in mac and len(mac) == 12:
            mac = ':'.join(mac[i:i + 2] for i in range(0, 12, 2))

        if mac.count(':') == 5:
            if mac in {"00:00:00:00:00:00", "FF:FF:FF:FF:FF:FF"}:
                return ""
            return mac

        return ""

    def process_discovered_macs(self, mac_addresses):
        """Track newly discovered MAC addresses and award points once per device."""
        normalized = {self.normalize_mac(mac) for mac in mac_addresses}
        normalized.discard("")

        if not normalized:
            return 0, 0

        with self._stats_lock:
            mac_points = self.gamification_data.setdefault("mac_points", {})
            new_mac_count = 0
            points_awarded = 0

            for mac in normalized:
                if mac in mac_points:
                    continue
                mac_points[mac] = {
                    "points": self.points_per_mac,
                    "first_seen": datetime.utcnow().isoformat() + "Z"
                }
                new_mac_count += 1
                points_awarded += self.points_per_mac

            if points_awarded:
                previous_points = self.gamification_data.get("total_points", 0)
                self.gamification_data["total_points"] = int(previous_points) + points_awarded
                prev_level = self.levelnbr
                self._update_gamification_state()
                self.save_gamification_data()
                logger.info(
                    f"Awarded {points_awarded} points for {new_mac_count} new MAC address(es). "
                    f"Level {prev_level} -> {self.levelnbr}"
                )

            return new_mac_count, points_awarded

    def delete_webconsolelog(self):
            """Delete the web console log file."""
            try:
                if os.path.exists(self.webconsolelog):
                    os.remove(self.webconsolelog)
                    logger.info(f"Deleted web console log file at {self.webconsolelog}")
                    #recreate the file

                else:
                    logger.info(f"Web console log file not found at {self.webconsolelog} ...")

            except OSError as e:
                logger.error(f"OS error occurred while deleting web console log file: {e}")
            except Exception as e:
                logger.error(f"Unexpected error occurred while deleting web console log file: {e}")

    def create_livestatusfile(self):
        """Create the live status file, it will be used to store the current status of the scan."""
        try:
            if not os.path.exists(self.livestatusfile):
                with open(self.livestatusfile, 'w', newline='') as csvfile:
                    csvwriter = csv.writer(csvfile)
                    csvwriter.writerow(['Total Open Ports', 'Alive Hosts Count', 'All Known Hosts Count', 'Vulnerabilities Count'])
                    csvwriter.writerow([0, 0, 0, 0])
                logger.info(f"Created live status file at {self.livestatusfile}")
            else:
                logger.info(f"Live status file already exists at {self.livestatusfile}")
        except OSError as e:
            logger.error(f"OS error occurred while creating live status file: {e}")
        except Exception as e:
            logger.error(f"Unexpected error occurred while creating live status file: {e}")


    def generate_actions_json(self):
        """Generate the actions JSON file, it will be used to store the actions configuration."""
        actions_dir = self.actions_dir
        actions_config = []
        try:
            for filename in os.listdir(actions_dir):
                if filename.endswith('.py') and filename != '__init__.py':
                    module_name = filename[:-3]
                    try:
                        module = importlib.import_module(f'actions.{module_name}')
                        b_class = getattr(module, 'b_class')
                        b_status = getattr(module, 'b_status')
                        b_port = getattr(module, 'b_port', None)
                        b_parent = getattr(module, 'b_parent', None)
                        actions_config.append({
                            "b_module": module_name,
                            "b_class": b_class,
                            "b_port": b_port,
                            "b_status": b_status,
                            "b_parent": b_parent
                        })
                        #add each b_class to the status list
                        self.status_list.append(b_class)
                    except AttributeError as e:
                        logger.error(f"Module {module_name} is missing required attributes: {e}")
                    except ImportError as e:
                        logger.error(f"Error importing module {module_name}: {e}")
                    except Exception as e:
                        logger.error(f"Unexpected error while processing module {module_name}: {e}")
            
            try:
                with open(self.actions_file, 'w') as file:
                    json.dump(actions_config, file, indent=4)
            except IOError as e:
                logger.error(f"Error writing to file {self.actions_file}: {e}")
            except Exception as e:
                logger.error(f"Unexpected error while writing to file {self.actions_file}: {e}")
        except Exception as e:
            logger.error(f"Unexpected error in generate_actions_json: {e}")


    def initialize_csv(self):
        """Initialize the network knowledge base CSV file with headers."""
        logger.info("Initializing the network knowledge base CSV file with headers")
        try:
            if not os.path.exists(self.netkbfile):
                try:
                    with open(self.actions_file, 'r') as file:
                        actions = json.load(file)
                    action_names = [action["b_class"] for action in actions if "b_class" in action]
                except FileNotFoundError as e:
                    logger.error(f"Actions file not found: {e}")
                    return
                except json.JSONDecodeError as e:
                    logger.error(f"Error decoding JSON from actions file: {e}")
                    return
                except Exception as e:
                    logger.error(f"Unexpected error reading actions file: {e}")
                    return

                headers = ["MAC Address", "IPs", "Hostnames", "Alive", "Ports", "Failed_Pings"] + action_names

                try:
                    with open(self.netkbfile, 'w', newline='') as file:
                        writer = csv.writer(file)
                        writer.writerow(headers)
                    logger.info(f"Network knowledge base CSV file created at {self.netkbfile}")
                except IOError as e:
                    logger.error(f"Error writing to netkbfile: {e}")
                except Exception as e:
                    logger.error(f"Unexpected error while writing to netkbfile: {e}")
            else:
                logger.info(f"Network knowledge base CSV file already exists at {self.netkbfile}")
        except Exception as e:
            logger.error(f"Unexpected error in initialize_csv: {e}")


    def load_config(self):
        """Load the configuration from the shared configuration JSON file."""
        try:
            logger.info("Loading configuration...")
            if os.path.exists(self.shared_config_json):
                with open(self.shared_config_json, 'r') as f:
                    config = json.load(f)
                    config = self._normalize_config_keys(config)
                    self.config.update(config)
                    self.config = self._normalize_config_keys(self.config)
                    for key, value in self.config.items():
                        setattr(self, key, value)
                    self._remove_legacy_attributes()
            else:
                logger.warning("Configuration file not found, creating new one with default values...")
                self.save_config()
                self.load_config()
                time.sleep(2)
        except FileNotFoundError:
            logger.error("Error loading configuration: File not found.")
            self.save_config()

    def save_config(self):
        """Save the configuration to the shared configuration JSON file."""
        logger.info("Saving configuration...")
        try:
            if not os.path.exists(self.configdir):
                os.makedirs(self.configdir)
                logger.info(f"Created configuration directory at {self.configdir}")
            try:
                self.config = self._normalize_config_keys(self.config)
                with open(self.shared_config_json, 'w') as f:
                    json.dump(self.config, f, indent=4)
                logger.info(f"Configuration saved to {self.shared_config_json}")
            except IOError as e:
                logger.error(f"Error writing to configuration file: {e}")
            except Exception as e:
                logger.error(f"Unexpected error while writing to configuration file: {e}")
        except OSError as e:
            logger.error(f"OS error while creating configuration directory: {e}")
        except Exception as e:
            logger.error(f"Unexpected error in save_config: {e}")

    def load_fonts(self):
        """Load the fonts."""
        try:
            logger.info("Loading fonts...")
            self.font_arial14 = self.load_font('Arial.ttf', 14)
            self.font_arial11 = self.load_font('Arial.ttf', 11)
            self.font_arial9 = self.load_font('Arial.ttf', 9)
            self.font_arialbold = self.load_font('Arial.ttf', 12)
            self.font_viking = self.load_font('Viking.TTF', 13)

        except Exception as e:
            logger.error(f"Error loading fonts: {e}")
            raise

    def load_font(self, font_name, size):
        """Load a font."""
        try:
            return ImageFont.truetype(os.path.join(self.fontdir, font_name), size)
        except Exception as e:
            logger.error(f"Error loading font {font_name}: {e}")
            raise

    def load_images(self):
        """Load the images for the e-paper display."""
        try:
            logger.info("Loading images...")

            # Load static images from the root of staticpicdir
            self.ragnarstatusimage = None
            self.ragnar1 = self.load_image(os.path.join(self.staticpicdir, 'ragnar1.bmp')) # Used to calculate the center of the screen
            self.port = self.load_image(os.path.join(self.staticpicdir, 'port.bmp'))
            self.frise = self.load_image(os.path.join(self.staticpicdir, 'frise.bmp'))
            self.target = self.load_image(os.path.join(self.staticpicdir, 'target.bmp'))
            self.vuln = self.load_image(os.path.join(self.staticpicdir, 'vuln.bmp'))
            self.connected = self.load_image(os.path.join(self.staticpicdir, 'connected.bmp'))
            self.bluetooth = self.load_image(os.path.join(self.staticpicdir, 'bluetooth.bmp'))
            self.wifi = self.load_image(os.path.join(self.staticpicdir, 'wifi.bmp'))
            self.ethernet = self.load_image(os.path.join(self.staticpicdir, 'ethernet.bmp'))
            self.usb = self.load_image(os.path.join(self.staticpicdir, 'usb.bmp'))
            self.level = self.load_image(os.path.join(self.staticpicdir, 'level.bmp'))
            self.cred = self.load_image(os.path.join(self.staticpicdir, 'cred.bmp'))
            self.attack = self.load_image(os.path.join(self.staticpicdir, 'attack.bmp'))
            self.attacks = self.load_image(os.path.join(self.staticpicdir, 'attacks.bmp'))
            self.gold = self.load_image(os.path.join(self.staticpicdir, 'gold.bmp'))
            self.networkkb = self.load_image(os.path.join(self.staticpicdir, 'networkkb.bmp'))
            self.zombie = self.load_image(os.path.join(self.staticpicdir, 'zombie.bmp'))
            self.data = self.load_image(os.path.join(self.staticpicdir, 'data.bmp'))
            self.money = self.load_image(os.path.join(self.staticpicdir, 'money.bmp'))
            self.zombie_status = self.load_image(os.path.join(self.staticpicdir, 'zombie.bmp'))
            self.attack = self.load_image(os.path.join(self.staticpicdir, 'attack.bmp'))

            """ Load the images for the different actions status"""
            # Dynamically load status images based on actions.json
            try:
                with open(self.actions_file, 'r') as f:
                    actions = json.load(f)
                    for action in actions:
                        b_class = action.get('b_class')
                        if b_class:
                            indiv_status_path = os.path.join(self.statuspicdir, b_class)
                            image_path = os.path.join(indiv_status_path, f'{b_class}.bmp')
                            image = self.load_image(image_path)
                            setattr(self, b_class, image)
                            logger.info(f"Loaded image for {b_class} from {image_path}")
            except Exception as e:
                logger.error(f"Error loading images from actions file: {e}")

            # Load image series dynamically from subdirectories
            self.image_series = {}
            for status in self.status_list:
                self.image_series[status] = []
                status_dir = os.path.join(self.statuspicdir, status)
                if not os.path.isdir(status_dir):
                    os.makedirs(status_dir)
                    logger.warning(f"Directory {status_dir} did not exist and was created.")
                    logger.warning(f" {status} wil use the IDLE images till you add some images in the {status} folder")

                for image_name in os.listdir(status_dir):
                    if image_name.endswith('.bmp') and re.search(r'\d', image_name):
                        image = self.load_image(os.path.join(status_dir, image_name))
                        if image:
                            self.image_series[status].append(image)

            if not self.image_series:
                logger.error("No images loaded.")
            else:
                for status, images in self.image_series.items():
                    logger.info(f"Loaded {len(images)} images for status {status}.")


            """Calculate the position of the Ragnar image on the screen to center it"""
            if self.ragnar1 is not None:
                self.x_center1 = (self.width - self.ragnar1.width) // 2
                self.y_bottom1 = self.height - self.ragnar1.height
            else:
                logger.warning("ragnar1.bmp image not found, using default positioning")
                self.x_center1 = self.width // 2  # Center horizontally
                self.y_bottom1 = self.height - 20  # Default bottom position

        except Exception as e:
            logger.error(f"Error loading images: {e}")
            raise

    def update_ragnarstatus(self):
        """ Using getattr to obtain the reference of the attribute with the name stored in self.ragnarorch_status"""
        try:
            self.ragnarstatusimage = getattr(self, self.ragnarorch_status)
            if self.ragnarstatusimage is None:
                raise AttributeError
        except AttributeError:
            logger.warning(f"The image for status {self.ragnarorch_status} is not available, using IDLE image by default.")
            self.ragnarstatusimage = self.attack
        
        self.ragnarstatustext = self.ragnarorch_status  # Mettre Ã  jour le texte du statut


    def load_image(self, image_path):

        """Load an image."""
        try:
            if not os.path.exists(image_path):
                logger.warning(f"Warning: {image_path} does not exist.")
                return None
            return Image.open(image_path)
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {e}")
            raise

    def update_image_randomizer(self):
        """Update the image randomizer and the imagegen variable."""
        try:
            status = self.ragnarstatustext
            if status in self.image_series and self.image_series[status]:
                random_index = random.randint(0, len(self.image_series[status]) - 1)
                self.imagegen = self.image_series[status][random_index]
                self.x_center = (self.width - self.imagegen.width) // 2
                self.y_bottom = self.height - self.imagegen.height
            else:
                logger.warning(f"Warning: No images available for status {status}, defaulting to IDLE images.")
                if "IDLE" in self.image_series and self.image_series["IDLE"]:
                    random_index = random.randint(0, len(self.image_series["IDLE"]) - 1)
                    self.imagegen = self.image_series["IDLE"][random_index]
                    self.x_center = (self.width - self.imagegen.width) // 2
                    self.y_bottom = self.height - self.imagegen.height
                else:
                    logger.error("No IDLE images available either.")
                    self.imagegen = None
        except Exception as e:
            logger.error(f"Error updating image randomizer: {e}")
            self.imagegen = None

    def wrap_text(self, text, font, max_width):
        """Wrap text to fit within a specified width when rendered."""
        try:
            lines = []
            words = text.split()
            while words:
                line = ''
                while words and font.getlength(line + words[0]) <= max_width:
                    line = line + (words.pop(0) + ' ')
                lines.append(line)
            return lines
        except Exception as e:
            logger.error(f"Error wrapping text: {e}")
            raise


    def set_latest_scan_results(self, scan_data):
        """Store fresh scan results in memory for immediate orchestrator access.
        
        Args:
            scan_data: List of dictionaries with keys: 'MAC Address', 'IPs', 'Hostnames', 'Alive', 'Ports', etc.
        """
        with self._scan_results_lock:
            self.latest_scan_results = scan_data
            self.latest_scan_timestamp = time.time()
            logger.info(f"ðŸ“‹ Stored {len(scan_data)} live hosts in memory for immediate orchestrator access")
    
    def get_latest_scan_results(self):
        """Retrieve fresh scan results from memory if available.
        
        Returns:
            List of host dictionaries if available, None otherwise
        """
        with self._scan_results_lock:
            if self.latest_scan_results is not None:
                age_seconds = time.time() - self.latest_scan_timestamp
                logger.info(f"ðŸ“‹ Retrieved {len(self.latest_scan_results)} hosts from memory (age: {age_seconds:.1f}s)")
            return self.latest_scan_results
    
    def read_data(self):
        """
        Read data from SQLite database.
        Returns data in the same format as CSV for backward compatibility.
        """
        data = []
        
        try:
            # Read from SQLite database (PRIMARY AND ONLY DATA SOURCE)
            hosts = self.db.get_all_hosts()
            
            if not hosts:
                logger.debug("No hosts found in database")
                return []
            
            # Convert database format to CSV-compatible format
            for host in hosts:
                # Convert to format expected by orchestrator
                row = {
                    'MAC Address': host.get('mac', ''),
                    'IPs': host.get('ip', ''),
                    'Hostnames': host.get('hostname', ''),
                    'Alive': '1' if host.get('status') == 'alive' else '0',
                    'Ports': host.get('ports', ''),
                    'Failed_Pings': str(host.get('failed_ping_count', 0)),
                    'Services': host.get('services', ''),
                    'Nmap Vulnerabilities': host.get('vulnerabilities', ''),
                    'Alive Count': str(host.get('alive_count', 0)),
                    'Network Profile': host.get('network_profile', ''),
                    'Scanner': host.get('scanner_status', ''),
                    'ssh_connector': host.get('ssh_connector', ''),
                    'rdp_connector': host.get('rdp_connector', ''),
                    'ftp_connector': host.get('ftp_connector', ''),
                    'smb_connector': host.get('smb_connector', ''),
                    'telnet_connector': host.get('telnet_connector', ''),
                    'sql_connector': host.get('sql_connector', ''),
                    'steal_files_ssh': host.get('steal_files_ssh', ''),
                    'steal_files_rdp': host.get('steal_files_rdp', ''),
                    'steal_files_ftp': host.get('steal_files_ftp', ''),
                    'steal_files_smb': host.get('steal_files_smb', ''),
                    'steal_files_telnet': host.get('steal_files_telnet', ''),
                    'steal_data_sql': host.get('steal_data_sql', ''),
                    'nmap_vuln_scanner': host.get('nmap_vuln_scanner', ''),
                    'Notes': host.get('notes', ''),
                    'Deep_Scanned': '',  # TODO: Add to database schema
                    'Deep_Scan_Ports': '',  # TODO: Add to database schema
                }
                data.append(row)
            
            logger.debug(f"âœ… Read {len(data)} hosts from SQLite database")
            return data
            
        except Exception as e:
            logger.error(f"Error reading from database: {e}")
            logger.debug(f"Traceback: {traceback.format_exc()}")
            return []  # Return empty list on database error
    

    def _start_cleanup_task(self):
        """Start background task to cleanup old hosts (not seen in 24 hours)."""
        def cleanup_worker():
            import time
            while True:
                try:
                    # Run cleanup every hour
                    time.sleep(3600)
                    removed = self.db.cleanup_old_hosts(hours=24)
                    if removed > 0:
                        logger.info(f"ðŸ§¹ Cleanup: Removed {removed} hosts not seen in 24 hours")
                except Exception as e:
                    logger.error(f"Error in cleanup task: {e}")
        
        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True, name="HostCleanup")
        cleanup_thread.start()
        logger.info("Started background host cleanup task (runs hourly)")

    def write_data(self, data):
        """
        DEPRECATED: CSV write operations no longer supported.
        All data is now stored in SQLite database.
        Use db.upsert_host() to write host data.
        This method is kept for backward compatibility but does nothing.
        """
        logger.warning("write_data() is deprecated - all data is now stored in SQLite database")
        logger.debug(f"Ignoring write_data call with {len(data) if data else 0} entries")
        pass

    def update_stats(self, persist=True):
        """Update gamification stats using lifetime achievements and SQLite database statistics."""
        with self._stats_lock:
            # Get current statistics from SQLite database
            try:
                db_stats = self.db.get_stats()
                # NOTE: Do NOT update vulnnbr here - it's managed by sync_vulnerability_count()
                # which uses network intelligence (114 vulns) instead of just database hosts_with_vulns (3)
                
                # Update zombie count from database (could be hosts with successful attacks)
                if 'total_hosts' in db_stats:
                    # This is a placeholder - adjust based on actual zombie logic
                    pass
            except Exception as e:
                logger.error(f"Failed to get stats from database: {e}")
            
            lifetime_counts = self.gamification_data.setdefault("lifetime_counts", {})
            total_added = 0
            awarded_breakdown = {}

            metrics = {
                "crednbr": (int(self.crednbr or 0), self.points_per_credential),
                "datanbr": (int(self.datanbr or 0), self.points_per_data_file),
                "zombiesnbr": (int(self.zombiesnbr or 0), self.points_per_zombie),
                "vulnnbr": (int(self.vulnnbr or 0), self.points_per_vulnerability),
            }

            for key, (current_value, points_value) in metrics.items():
                recorded_value = int(lifetime_counts.get(key, 0) or 0)
                if current_value > recorded_value:
                    delta = current_value - recorded_value
                    lifetime_counts[key] = current_value
                    points_gained = delta * points_value
                    total_added += points_gained
                    awarded_breakdown[key] = {
                        "delta": delta,
                        "points": points_gained
                    }
                else:
                    lifetime_counts[key] = max(recorded_value, current_value)

            if total_added:
                self.gamification_data["total_points"] = int(self.gamification_data.get("total_points", 0)) + total_added
                logger.info(f"Awarded {total_added} points from new achievements: {awarded_breakdown}")

            previous_points = self.coinnbr
            previous_level = self.levelnbr
            self._update_gamification_state()

            if persist and (total_added or self.coinnbr != previous_points or self.levelnbr != previous_level):
                self.save_gamification_data()

            return total_added


    def print(self, message):
        """Print a debug message if debug mode is enabled."""
        if self.config['debug_mode']:
            logger.debug(message)
